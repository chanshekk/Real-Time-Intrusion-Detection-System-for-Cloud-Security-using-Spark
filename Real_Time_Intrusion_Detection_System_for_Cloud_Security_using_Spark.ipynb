{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanshekk/Real-Time-Intrusion-Detection-System-for-Cloud-Security-using-Spark/blob/main/Real_Time_Intrusion_Detection_System_for_Cloud_Security_using_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDhbyZxOoIb7",
        "outputId": "18779956-bf3d-4e12-8070-c57ad7339a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged dataset saved as 'UNSW_NB15_full.csv'\n",
            "Shape of merged dataset: (257673, 45)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load training and testing datasets\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/UNSW_NB15_Dataset/UNSW_NB15_training-set.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/UNSW_NB15_Dataset/UNSW_NB15_testing-set.csv\")\n",
        "\n",
        "# Merge datasets vertically (row-wise)\n",
        "merged_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "\n",
        "# Save the merged dataset to a new CSV file\n",
        "merged_df.to_csv(\"UNSW_NB15_full.csv\", index=False)\n",
        "\n",
        "print(\"Merged dataset saved as 'UNSW_NB15_full.csv'\")\n",
        "print(\"Shape of merged dataset:\", merged_df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hCCDHvV-bVOD"
      },
      "outputs": [],
      "source": [
        "# ================== Part 0: Setup and Preprocessing ==================\n",
        "!pip install -q pyspark\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, VectorSlicer\n",
        "from pyspark.ml.classification import DecisionTreeClassifier as SparkDTClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AMwL4EOTbdBH"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/UNSW_NB15_full.csv\")\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['attack_cat'])\n",
        "\n",
        "drop_cols = ['id', 'attack_cat', 'label_name', 'proto', 'service', 'state']\n",
        "df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
        "\n",
        "X = df.drop(\"label\", axis=1)\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Handle NaNs\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "X = pd.DataFrame(X_imputed, columns=X.columns)\n",
        "\n",
        "# Standardize features for non-FS parts\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXl7kGdkbuM_",
        "outputId": "2e335b20-87f7-4cb3-dd94-dbe1e33f29d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Part 1: Execution without Feature Selection on Spark ===\n",
            "Execution Time: 5.49 seconds\n",
            "Accuracy: 0.7989832087138754\n",
            "F1-score: 0.7731410561786786\n",
            "Confusion Matrix:\n",
            " [[   39     1    13   515    81     0   135     0     0     0]\n",
            " [    0    17    13   554    75     8     9    12     8     0]\n",
            " [    2     3   303  4385   143    13    63    31    15     0]\n",
            " [    1    11   193 12130   408    57   366   132    28     2]\n",
            " [    0     4    26  1365  3211     1  2565    12    40     0]\n",
            " [    0     3    21   285    39 17223    11     6     1     0]\n",
            " [    0     0    13   628  1406     1 25913    35    29     1]\n",
            " [    0     0    26  1110   104     1    94  2850     8     0]\n",
            " [    0     0    17   282    35     2    22    31    68     0]\n",
            " [    0     0     0    34     2     1     1     0     0     9]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.05      0.09       784\n",
            "           1       0.44      0.02      0.05       696\n",
            "           2       0.48      0.06      0.11      4958\n",
            "           3       0.57      0.91      0.70     13328\n",
            "           4       0.58      0.44      0.50      7224\n",
            "           5       1.00      0.98      0.99     17589\n",
            "           6       0.89      0.92      0.91     28026\n",
            "           7       0.92      0.68      0.78      4193\n",
            "           8       0.35      0.15      0.21       457\n",
            "           9       0.75      0.19      0.31        47\n",
            "\n",
            "    accuracy                           0.80     77302\n",
            "   macro avg       0.69      0.44      0.46     77302\n",
            "weighted avg       0.80      0.80      0.77     77302\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ================== Part 1: Execution without Feature Selection on Spark ==================\n",
        "start1 = time.time()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "model1 = DecisionTreeClassifier(max_depth=10)\n",
        "model1.fit(X_train, y_train)\n",
        "y_pred1 = model1.predict(X_test)\n",
        "\n",
        "end1 = time.time()\n",
        "\n",
        "print(\"\\n=== Part 1: Execution without Feature Selection on Spark ===\")\n",
        "print(\"Execution Time: {:.2f} seconds\".format(end1 - start1))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred1))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred1, average='weighted'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred1))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obfASZd7yLQK",
        "outputId": "8e586396-6d51-49a0-e1e7-ac3d6a65bf26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Part 2: Execution Without Feature Selection ===\n",
            "Execution Time: 156.06 seconds\n",
            "Accuracy: 0.7997100999119946\n",
            "F1-score: 0.7698961454335016\n",
            "Confusion Matrix:\n",
            " [[   47     0     0   600    75     0   128     0     0     0]\n",
            " [    0    21     5   579    80     1    14     8     7     0]\n",
            " [    1     2   179  4420   138     7    68    28    42     0]\n",
            " [    7     3    55 12166   480     9   359   254    53     0]\n",
            " [    4     0    10  1037  3033     1  3098    54    39     0]\n",
            " [    0     1    32   334    32 17159    17     2     8     0]\n",
            " [    7     0     7   463  1277     0 26131    60    36     0]\n",
            " [    0     1     4  1008    80     0    85  2900     8     0]\n",
            " [    0     0    15   172    42     1    25    36   156     0]\n",
            " [    0     0     0    48     8     0     1     0     0     0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.06      0.10       850\n",
            "           1       0.75      0.03      0.06       715\n",
            "           2       0.58      0.04      0.07      4885\n",
            "           3       0.58      0.91      0.71     13386\n",
            "           4       0.58      0.42      0.48      7276\n",
            "           5       1.00      0.98      0.99     17585\n",
            "           6       0.87      0.93      0.90     27981\n",
            "           7       0.87      0.71      0.78      4086\n",
            "           8       0.45      0.35      0.39       447\n",
            "           9       0.00      0.00      0.00        57\n",
            "\n",
            "    accuracy                           0.80     77268\n",
            "   macro avg       0.64      0.44      0.45     77268\n",
            "weighted avg       0.80      0.80      0.77     77268\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# ================== Part 2: Execution without Feature Selection ==================\n",
        "start2 = time.time()\n",
        "\n",
        "spark = SparkSession.builder.appName(\"UNSW-NB15\").getOrCreate()\n",
        "spark_df = spark.createDataFrame(pd.DataFrame(X_scaled, columns=X.columns).assign(label=y.values))\n",
        "spark_df = spark_df.na.drop()\n",
        "\n",
        "assembler = VectorAssembler(inputCols=X.columns.tolist(), outputCol=\"features\")\n",
        "spark_df = assembler.transform(spark_df)\n",
        "\n",
        "train_spark, test_spark = spark_df.randomSplit([0.7, 0.3], seed=42)\n",
        "dt_spark = SparkDTClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=10)\n",
        "model2 = dt_spark.fit(train_spark)\n",
        "pred2 = model2.transform(test_spark)\n",
        "\n",
        "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "pred_df2 = pred2.select(\"label\", \"prediction\").toPandas()\n",
        "\n",
        "end2 = time.time()\n",
        "\n",
        "print(\"\\n=== Part 2: Execution Without Feature Selection ===\")\n",
        "print(\"Execution Time: {:.2f} seconds\".format(end2 - start2))\n",
        "print(\"Accuracy:\", accuracy_score(pred_df2[\"label\"], pred_df2[\"prediction\"]))\n",
        "print(\"F1-score:\", evaluator2.evaluate(pred2))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(pred_df2[\"label\"], pred_df2[\"prediction\"]))\n",
        "print(\"Classification Report:\\n\", classification_report(pred_df2[\"label\"], pred_df2[\"prediction\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs0ETjhryLSV",
        "outputId": "012b142e-81b2-4ec9-8b1f-cfe49ef72d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Part 3: Execution With Feature Selection on Spark===\n",
            "Execution Time: 2.32 seconds\n",
            "Accuracy: 0.8039248661095444\n",
            "F1-score: 0.7719196440795272\n",
            "Confusion Matrix:\n",
            " [[   34     0     3   490   116     0   141     0     0     0]\n",
            " [    0    23     5   529   112     0    16     7     4     0]\n",
            " [    3     8   152  4396   144    17   143    30    65     0]\n",
            " [    6    25   112 12056   334    46   434   247    68     0]\n",
            " [    0     2    35   900  2903     7  3283    75    19     0]\n",
            " [    0     2    48   315    31 17158    23     5     7     0]\n",
            " [    0     0     9   407   938     3 26587    61    21     0]\n",
            " [    0     1     3   964    17     3   148  3050     7     0]\n",
            " [    0     0    10   102    41     3    69    50   182     0]\n",
            " [    0     0     9    34     2     0     2     0     0     0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.04      0.08       784\n",
            "           1       0.38      0.03      0.06       696\n",
            "           2       0.39      0.03      0.06      4958\n",
            "           3       0.60      0.90      0.72     13328\n",
            "           4       0.63      0.40      0.49      7224\n",
            "           5       1.00      0.98      0.99     17589\n",
            "           6       0.86      0.95      0.90     28026\n",
            "           7       0.87      0.73      0.79      4193\n",
            "           8       0.49      0.40      0.44       457\n",
            "           9       0.00      0.00      0.00        47\n",
            "\n",
            "    accuracy                           0.80     77302\n",
            "   macro avg       0.60      0.45      0.45     77302\n",
            "weighted avg       0.79      0.80      0.77     77302\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# ================== Part 3: Execution With Feature Selection on Spark ==================\n",
        "start3 = time.time()\n",
        "\n",
        "minmax_scaler = MinMaxScaler()\n",
        "X_minmax = minmax_scaler.fit_transform(X)\n",
        "\n",
        "selector = SelectKBest(score_func=chi2, k=20)\n",
        "X_selected = selector.fit_transform(X_minmax, y)\n",
        "\n",
        "X_train_fs, X_test_fs, y_train_fs, y_test_fs = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
        "model3 = DecisionTreeClassifier(max_depth=10)\n",
        "model3.fit(X_train_fs, y_train_fs)\n",
        "y_pred3 = model3.predict(X_test_fs)\n",
        "\n",
        "end3 = time.time()\n",
        "\n",
        "print(\"\\n=== Part 3: Execution With Feature Selection on Spark===\")\n",
        "print(\"Execution Time: {:.2f} seconds\".format(end3 - start3))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_fs, y_pred3))\n",
        "print(\"F1-score:\", f1_score(y_test_fs, y_pred3, average='weighted'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_fs, y_pred3))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_fs, y_pred3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD5OVz_6cF35",
        "outputId": "31db27a7-5dda-4d72-8cce-a5c285971f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Part 4: Spark With Feature Selection ===\n",
            "Execution Time: 65.86 seconds\n",
            "Accuracy: 0.800137184863074\n",
            "F1-score: 0.7709684910643314\n",
            "Confusion Matrix:\n",
            " [[   37     0    20   584    60     0   148     1     0     0]\n",
            " [    0    29    16   560    79     0    20     4     7     0]\n",
            " [    2     3   179  4323   171     3   107    27    70     0]\n",
            " [    9    12   181 11915   454    21   500   223    71     0]\n",
            " [    3     7    18   968  3086     5  3080    85    24     0]\n",
            " [    0     2    29   346    70 17116    12     1     9     0]\n",
            " [    1     3     8   390  1130     1 26354    56    38     0]\n",
            " [    0     1    63   890    61     0   129  2923    19     0]\n",
            " [    0     0    38    76    58     0    54    35   186     0]\n",
            " [    0     2     1    40    13     0     1     0     0     0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.04      0.08       850\n",
            "           1       0.49      0.04      0.07       715\n",
            "           2       0.32      0.04      0.07      4885\n",
            "           3       0.59      0.89      0.71     13386\n",
            "           4       0.60      0.42      0.50      7276\n",
            "           5       1.00      0.97      0.99     17585\n",
            "           6       0.87      0.94      0.90     27981\n",
            "           7       0.87      0.72      0.79      4086\n",
            "           8       0.44      0.42      0.43       447\n",
            "           9       0.00      0.00      0.00        57\n",
            "\n",
            "    accuracy                           0.80     77268\n",
            "   macro avg       0.59      0.45      0.45     77268\n",
            "weighted avg       0.78      0.80      0.77     77268\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# ================== Part 4: Execution with Feature Selection ==================\n",
        "start4 = time.time()\n",
        "\n",
        "selected_indices = selector.get_support(indices=True).tolist()\n",
        "slicer = VectorSlicer(inputCol=\"features\", outputCol=\"selectedFeatures\", indices=selected_indices)\n",
        "sliced_df = slicer.transform(spark_df)\n",
        "\n",
        "train_sel, test_sel = sliced_df.randomSplit([0.7, 0.3], seed=42)\n",
        "dt_sel = SparkDTClassifier(labelCol=\"label\", featuresCol=\"selectedFeatures\", maxDepth=10)\n",
        "model4 = dt_sel.fit(train_sel)\n",
        "pred4 = model4.transform(test_sel)\n",
        "\n",
        "evaluator4 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "pred_df4 = pred4.select(\"label\", \"prediction\").toPandas()\n",
        "\n",
        "end4 = time.time()\n",
        "\n",
        "print(\"\\n=== Part 4: Spark With Feature Selection ===\")\n",
        "print(\"Execution Time: {:.2f} seconds\".format(end4 - start4))\n",
        "print(\"Accuracy:\", accuracy_score(pred_df4[\"label\"], pred_df4[\"prediction\"]))\n",
        "print(\"F1-score:\", evaluator4.evaluate(pred4))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(pred_df4[\"label\"], pred_df4[\"prediction\"]))\n",
        "print(\"Classification Report:\\n\", classification_report(pred_df4[\"label\"], pred_df4[\"prediction\"]))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zibkzGYOv4ncQORzouE06Dd4dhUsdIJF",
      "authorship_tag": "ABX9TyPQwfsMKSmDLKagWwUY0q2m",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}