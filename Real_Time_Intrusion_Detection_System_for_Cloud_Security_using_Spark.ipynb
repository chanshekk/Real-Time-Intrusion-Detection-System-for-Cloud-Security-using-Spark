{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanshekk/Real-Time-Intrusion-Detection-System-for-Cloud-Security-using-Spark/blob/main/Real_Time_Intrusion_Detection_System_for_Cloud_Security_using_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDhbyZxOoIb7",
        "outputId": "bc1e7bad-043f-4a81-de66-43f7626963fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged dataset saved as 'UNSW_NB15_full.csv'\n",
            "Shape of merged dataset: (257673, 45)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load training and testing datasets\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/UNSW_NB15_Dataset/UNSW_NB15_training-set.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/UNSW_NB15_Dataset/UNSW_NB15_testing-set.csv\")\n",
        "\n",
        "# Merge datasets vertically (row-wise)\n",
        "merged_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "\n",
        "# Save the merged dataset to a new CSV file\n",
        "merged_df.to_csv(\"UNSW_NB15_full.csv\", index=False)\n",
        "\n",
        "print(\"Merged dataset saved as 'UNSW_NB15_full.csv'\")\n",
        "print(\"Shape of merged dataset:\", merged_df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCCDHvV-bVOD"
      },
      "outputs": [],
      "source": [
        "# ================== Part 0: Setup and Preprocessing ==================\n",
        "!pip install -q pyspark\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, VectorSlicer\n",
        "from pyspark.ml.classification import DecisionTreeClassifier as SparkDTClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMwL4EOTbdBH"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/UNSW_NB15_full.csv\")\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['attack_cat'])\n",
        "\n",
        "drop_cols = ['id', 'attack_cat', 'label_name', 'proto', 'service', 'state']\n",
        "df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
        "\n",
        "X = df.drop(\"label\", axis=1)\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Handle NaNs\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "X = pd.DataFrame(X_imputed, columns=X.columns)\n",
        "\n",
        "# Standardize features for non-FS parts\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXl7kGdkbuM_",
        "outputId": "622dcfcb-baa7-4702-c1bc-e8b56ce8b62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Part 1: Execution without Feature Selection on Spark ===\n",
            "Execution Time: 8.33 seconds\n",
            "Accuracy: 0.7989573361620657\n",
            "F1-score: 0.7731619744194524\n",
            "Confusion Matrix:\n",
            " [[   39     1    13   515    81     0   135     0     0     0]\n",
            " [    0    17    14   553    75     8     9    12     8     0]\n",
            " [    2     3   307  4383   143    11    63    31    15     0]\n",
            " [    1    11   193 12128   408    57   367   132    29     2]\n",
            " [    0     4    26  1364  3211     1  2566    12    40     0]\n",
            " [    0     3    21   286    39 17222    11     6     1     0]\n",
            " [    0     0    13   629  1406     1 25912    35    29     1]\n",
            " [    0     0    26  1110   104     1    94  2850     8     0]\n",
            " [    0     0    17   282    35     3    22    32    66     0]\n",
            " [    0     0     0    34     2     1     1     0     0     9]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.05      0.09       784\n",
            "           1       0.44      0.02      0.05       696\n",
            "           2       0.49      0.06      0.11      4958\n",
            "           3       0.57      0.91      0.70     13328\n",
            "           4       0.58      0.44      0.50      7224\n",
            "           5       1.00      0.98      0.99     17589\n",
            "           6       0.89      0.92      0.91     28026\n",
            "           7       0.92      0.68      0.78      4193\n",
            "           8       0.34      0.14      0.20       457\n",
            "           9       0.75      0.19      0.31        47\n",
            "\n",
            "    accuracy                           0.80     77302\n",
            "   macro avg       0.69      0.44      0.46     77302\n",
            "weighted avg       0.80      0.80      0.77     77302\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ================== Part 1: Execution without Feature Selection on Spark ==================\n",
        "start1 = time.time()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "model1 = DecisionTreeClassifier(max_depth=10)\n",
        "model1.fit(X_train, y_train)\n",
        "y_pred1 = model1.predict(X_test)\n",
        "\n",
        "end1 = time.time()\n",
        "\n",
        "print(\"\\n=== Part 1: Execution without Feature Selection on Spark ===\")\n",
        "print(\"Execution Time: {:.2f} seconds\".format(end1 - start1))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred1))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred1, average='weighted'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred1))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obfASZd7yLQK",
        "outputId": "0e01b2a3-f035-42d2-ef00-338988d95f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Part 2: Execution Without Feature Selection ===\n",
            "Execution Time: 159.19 seconds\n",
            "Accuracy: 0.7995289123569913\n",
            "F1-score: 0.7631682791661978\n",
            "Confusion Matrix:\n",
            " [[   44     0     0   626    41     0   134     5     0     0]\n",
            " [    0    43     6   567    47     1    27    13    11     0]\n",
            " [    3     2   141  4317    90    19   175    80    58     0]\n",
            " [    8    10    42 12171   332    25   530   209    55     4]\n",
            " [    4     0     5  1024  2285     1  3885    42    29     1]\n",
            " [    0     5    23   325    13 17169    32     8     7     3]\n",
            " [    7     0     0   462   653     0 26775    51    32     1]\n",
            " [    0     2     3   930    80     1   116  2943    11     0]\n",
            " [    0     0     1   102    36     8    51    56   193     0]\n",
            " [    0     0     0    38     4     0     1     0     0    14]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.05      0.10       850\n",
            "           1       0.69      0.06      0.11       715\n",
            "           2       0.64      0.03      0.06      4885\n",
            "           3       0.59      0.91      0.72     13386\n",
            "           4       0.64      0.31      0.42      7276\n",
            "           5       1.00      0.98      0.99     17585\n",
            "           6       0.84      0.96      0.90     27981\n",
            "           7       0.86      0.72      0.79      4086\n",
            "           8       0.49      0.43      0.46       447\n",
            "           9       0.61      0.25      0.35        57\n",
            "\n",
            "    accuracy                           0.80     77268\n",
            "   macro avg       0.70      0.47      0.49     77268\n",
            "weighted avg       0.80      0.80      0.76     77268\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ================== Part 2: Execution without Feature Selection ==================\n",
        "start2 = time.time()\n",
        "\n",
        "spark = SparkSession.builder.appName(\"UNSW-NB15\").getOrCreate()\n",
        "spark_df = spark.createDataFrame(pd.DataFrame(X_scaled, columns=X.columns).assign(label=y.values))\n",
        "spark_df = spark_df.na.drop()\n",
        "\n",
        "assembler = VectorAssembler(inputCols=X.columns.tolist(), outputCol=\"features\")\n",
        "spark_df = assembler.transform(spark_df)\n",
        "\n",
        "train_spark, test_spark = spark_df.randomSplit([0.7, 0.3], seed=42)\n",
        "dt_spark = SparkDTClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=10)\n",
        "model2 = dt_spark.fit(train_spark)\n",
        "pred2 = model2.transform(test_spark)\n",
        "\n",
        "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "pred_df2 = pred2.select(\"label\", \"prediction\").toPandas()\n",
        "\n",
        "end2 = time.time()\n",
        "\n",
        "print(\"\\n=== Part 2: Execution Without Feature Selection ===\")\n",
        "print(\"Execution Time: {:.2f} seconds\".format(end2 - start2))\n",
        "print(\"Accuracy:\", accuracy_score(pred_df2[\"label\"], pred_df2[\"prediction\"]))\n",
        "print(\"F1-score:\", evaluator2.evaluate(pred2))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(pred_df2[\"label\"], pred_df2[\"prediction\"]))\n",
        "print(\"Classification Report:\\n\", classification_report(pred_df2[\"label\"], pred_df2[\"prediction\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs0ETjhryLSV",
        "outputId": "7563d78e-64c9-42d2-b02e-b32cc06b4abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Part 3: Execution With Feature Selection on Spark===\n",
            "Execution Time: 1.66 seconds\n",
            "Accuracy: 0.8039248661095444\n",
            "F1-score: 0.7719664323254988\n",
            "Confusion Matrix:\n",
            " [[   34     0     3   490   116     0   141     0     0     0]\n",
            " [    0    23     5   529   112     0    16     7     4     0]\n",
            " [    3     7   154  4396   147    13   145    28    65     0]\n",
            " [    6    25   111 12056   336    45   434   247    68     0]\n",
            " [    0     2    36   900  2902     7  3283    75    19     0]\n",
            " [    0     2    49   315    31 17157    23     5     7     0]\n",
            " [    0     0     9   407   938     3 26587    61    21     0]\n",
            " [    0     1     4   964    17     2   148  3050     7     0]\n",
            " [    0     0    10   102    41     3    69    50   182     0]\n",
            " [    0     0     9    34     2     0     2     0     0     0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.04      0.08       784\n",
            "           1       0.38      0.03      0.06       696\n",
            "           2       0.39      0.03      0.06      4958\n",
            "           3       0.60      0.90      0.72     13328\n",
            "           4       0.63      0.40      0.49      7224\n",
            "           5       1.00      0.98      0.99     17589\n",
            "           6       0.86      0.95      0.90     28026\n",
            "           7       0.87      0.73      0.79      4193\n",
            "           8       0.49      0.40      0.44       457\n",
            "           9       0.00      0.00      0.00        47\n",
            "\n",
            "    accuracy                           0.80     77302\n",
            "   macro avg       0.60      0.45      0.45     77302\n",
            "weighted avg       0.79      0.80      0.77     77302\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# ================== Part 3: Execution With Feature Selection on Spark ==================\n",
        "start3 = time.time()\n",
        "\n",
        "minmax_scaler = MinMaxScaler()\n",
        "X_minmax = minmax_scaler.fit_transform(X)\n",
        "\n",
        "selector = SelectKBest(score_func=chi2, k=20)\n",
        "X_selected = selector.fit_transform(X_minmax, y)\n",
        "\n",
        "X_train_fs, X_test_fs, y_train_fs, y_test_fs = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
        "model3 = DecisionTreeClassifier(max_depth=10)\n",
        "model3.fit(X_train_fs, y_train_fs)\n",
        "y_pred3 = model3.predict(X_test_fs)\n",
        "\n",
        "end3 = time.time()\n",
        "\n",
        "print(\"\\n=== Part 3: Execution With Feature Selection on Spark===\")\n",
        "print(\"Execution Time: {:.2f} seconds\".format(end3 - start3))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_fs, y_pred3))\n",
        "print(\"F1-score:\", f1_score(y_test_fs, y_pred3, average='weighted'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_fs, y_pred3))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_fs, y_pred3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MD5OVz_6cF35",
        "outputId": "506733fe-b79a-41f0-8f53-0a1a9b209a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Part 4: Spark With Feature Selection ===\n",
            "Execution Time: 64.01 seconds\n",
            "Accuracy: 0.8002536625770047\n",
            "F1-score: 0.7698436204858861\n",
            "Confusion Matrix:\n",
            " [[   41     0    16   605    60     0   127     1     0     0]\n",
            " [    0    30    15   556    78     0    20     8     8     0]\n",
            " [    1     3   139  4431   144     6    60    38    63     0]\n",
            " [   12    12   146 12167   396    44   336   202    71     0]\n",
            " [    3     7    13   999  2988     8  3115   107    36     0]\n",
            " [    0     2    14   370    43 17133    13     2     8     0]\n",
            " [    1     3     7   510  1079     4 26238    88    51     0]\n",
            " [    0     1    17   985    56     0    98  2919    10     0]\n",
            " [    0     0     8   116    54     1    47    42   179     0]\n",
            " [    0     2     1    44     7     0     1     0     2     0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.05      0.09       850\n",
            "           1       0.50      0.04      0.08       715\n",
            "           2       0.37      0.03      0.05      4885\n",
            "           3       0.59      0.91      0.71     13386\n",
            "           4       0.61      0.41      0.49      7276\n",
            "           5       1.00      0.97      0.99     17585\n",
            "           6       0.87      0.94      0.90     27981\n",
            "           7       0.86      0.71      0.78      4086\n",
            "           8       0.42      0.40      0.41       447\n",
            "           9       0.00      0.00      0.00        57\n",
            "\n",
            "    accuracy                           0.80     77268\n",
            "   macro avg       0.59      0.45      0.45     77268\n",
            "weighted avg       0.79      0.80      0.77     77268\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# ================== Part 4: Execution with Feature Selection ==================\n",
        "start4 = time.time()\n",
        "\n",
        "selected_indices = selector.get_support(indices=True).tolist()\n",
        "slicer = VectorSlicer(inputCol=\"features\", outputCol=\"selectedFeatures\", indices=selected_indices)\n",
        "sliced_df = slicer.transform(spark_df)\n",
        "\n",
        "train_sel, test_sel = sliced_df.randomSplit([0.7, 0.3], seed=42)\n",
        "dt_sel = SparkDTClassifier(labelCol=\"label\", featuresCol=\"selectedFeatures\", maxDepth=10)\n",
        "model4 = dt_sel.fit(train_sel)\n",
        "pred4 = model4.transform(test_sel)\n",
        "\n",
        "evaluator4 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "pred_df4 = pred4.select(\"label\", \"prediction\").toPandas()\n",
        "\n",
        "end4 = time.time()\n",
        "\n",
        "print(\"\\n=== Part 4: Spark With Feature Selection ===\")\n",
        "print(\"Execution Time: {:.2f} seconds\".format(end4 - start4))\n",
        "print(\"Accuracy:\", accuracy_score(pred_df4[\"label\"], pred_df4[\"prediction\"]))\n",
        "print(\"F1-score:\", evaluator4.evaluate(pred4))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(pred_df4[\"label\"], pred_df4[\"prediction\"]))\n",
        "print(\"Classification Report:\\n\", classification_report(pred_df4[\"label\"], pred_df4[\"prediction\"]))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zibkzGYOv4ncQORzouE06Dd4dhUsdIJF",
      "authorship_tag": "ABX9TyPQwfsMKSmDLKagWwUY0q2m",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}